# ML-Based Tagging Configuration
# Parameters for automated panel tagging using machine learning

# Character detection & recognition
character_detection:
  enabled: true

  # Object detection (YOLO)
  object_detector:
    model: "yolov8n.pt"           # Model file (n=nano, s=small, m=medium, l=large)
    confidence: 0.6               # Minimum confidence for detection
    device: "cuda"                # Device: "cuda", "cpu", or "mps" (Mac)
    fallback_to_cpu: true         # Fall back to CPU if GPU unavailable

  # Face detection (manga-specific)
  face_detector:
    model: "lbpcascade_animeface.xml"
    scale_factor: 1.1
    min_neighbors: 5
    min_size: [30, 30]

  # Character identification (face recognition)
  face_recognition:
    model: "hog"                  # "hog" (CPU-friendly) or "cnn" (GPU, more accurate)
    tolerance: 0.6                # Lower = stricter matching (0.0-1.0)
    num_jitters: 1                # More jitters = slower but more accurate

  # Character embeddings database
  embeddings:
    database_path: "data/character_embeddings.pkl"
    min_samples_per_character: 10 # Minimum face samples to build embedding
    update_on_correction: true    # Update embeddings when user corrects tags

# Emotion detection
emotion_detection:
  enabled: true

  model:
    backend: "deepface"           # "deepface", "fer", or "custom"
    framework: "vgg16"            # "vgg16", "densenet121", "resnet50"
    confidence: 0.6               # Minimum confidence for emotion tags

  emotions:
    # Map model outputs to our taxonomy
    basic: ["happy", "sad", "angry", "fearful", "disgusted", "surprised", "neutral"]

  per_character: true             # Detect emotions per character vs overall panel
  fallback_to_overall: true       # If per-character fails, detect overall mood

# Text & dialogue detection
dialogue_detection:
  enabled: true

  # Speech bubble detection
  bubble_detector:
    model: "bubble_yolov8.pt"     # Fine-tuned YOLO for speech bubbles
    confidence: 0.7
    device: "cuda"
    fallback_to_cpu: true

  # OCR (text extraction)
  ocr:
    primary: "manga-ocr"          # "manga-ocr", "tesseract", "easyocr"
    fallback: "tesseract"         # Fallback if primary fails
    languages: ["eng", "jpn"]     # Supported languages
    confidence: 0.5

  # Text analysis
  analysis:
    detect_language: true
    extract_speaker: true         # Try to match dialogue to characters
    sentiment_analysis: false     # Experimental

# Scene & mood analysis
scene_analysis:
  enabled: true

  # Scene classification
  scene_classifier:
    model: "places365"            # Pre-trained scene classifier
    top_k: 3                      # Return top K scene predictions
    confidence: 0.3

  # Color palette analysis
  color_analysis:
    enabled: true
    num_clusters: 5               # Number of dominant colors to extract
    mood_mapping:                 # Map color properties to moods
      dark_threshold: 100         # Below this brightness = dark moods
      bright_threshold: 180       # Above this brightness = bright moods
      saturation_threshold: 50

  # Action/intensity detection
  intensity_detection:
    enabled: true
    edge_density_threshold:       # Edge density ranges for intensity
      calm: 0.05                  # Below = calm
      normal: 0.10
      intense: 0.15               # Above = intense/chaotic
    detect_motion_blur: true
    detect_action_lines: true

# Confidence scoring & aggregation
confidence:
  thresholds:
    high: 0.85                    # Auto-accept, no review
    medium: 0.70                  # Accept with flag for spot-check
    low: 0.50                     # Requires manual review
    very_low: 0.30                # Discard, manual tagging needed

  weighting:                      # Weight for each component in overall score
    character: 0.35
    emotion: 0.20
    dialogue: 0.25
    scene: 0.20

  require_minimum:                # Require minimum confidence in key areas
    character: true               # Must have decent character detection
    dialogue: false               # OK if no dialogue detected

# Batch processing
batch_processing:
  enabled: true
  batch_size: 16                  # Number of panels to process at once
  prefetch: true                  # Prefetch next batch while processing
  num_workers: 2                  # Parallel data loading workers

  # Memory management
  max_gpu_memory_gb: 8            # Limit GPU memory usage
  clear_cache_every: 100          # Clear cache every N batches

# Checkpointing (resume interrupted processing)
checkpointing:
  enabled: true
  checkpoint_file: "data/ml_processing_checkpoint.json"
  save_interval: 50               # Save every N panels
  auto_resume: true               # Automatically resume from checkpoint

# Training & fine-tuning
training:
  enabled: false                  # Set to true when fine-tuning models

  data_collection:
    min_training_samples: 500     # Minimum samples for fine-tuning
    validation_split: 0.2

  fine_tuning:
    learning_rate: 0.0001
    epochs: 10
    batch_size: 32

  continuous_learning:
    enabled: true                 # Learn from manual corrections
    update_interval: 100          # Retrain after N corrections

# Fallback strategies
fallback:
  on_gpu_oom:                     # Out of memory
    reduce_batch_size: true
    switch_to_cpu: true

  on_model_error:
    use_fallback_model: true
    skip_component: false         # vs. skip entire panel

  on_low_confidence:
    flag_for_review: true
    use_conservative_tags: true   # Only include high-confidence results

# Performance monitoring
monitoring:
  enabled: true
  log_processing_time: true
  log_confidence_scores: true
  log_errors: true
  generate_report: true
  report_path: "data/ml_tagging_report.json"
